Article ID:	CQG/265039/SPE
Title:	Report on the second mock LISA data challenge
 	
=== Responses to the first referee's report ===

> The manuscript is devoted to the description of the results of the 2nd
> round of the Mock LISA Data Challenges (MLDC). I recommend the paper for
> publication, but the Authors should consider the following suggestions.
> 
> 1. Page 3, 6th line from the top. The sentence starting with
> "Data set 2.2 ..." contains two unclear phrases.
> (i) It is not clear what "a different realization of the Galaxy" means?

All Challenge-2 Galaxies were generated by randomizing the individual-binary
parameters of a seed Galaxy provided by Gijs Nelemans. The randomization is
such that the "accidental" binary parameters (such as orientations) are
completely random, while the more "substantial" parameters (such as frequency
and sky position) are changed by little, so that the Galaxy maintains its
statistical properties (but the individual system parameters cannot be used to
cheat in the challenge).

We have changed the text from "a different realization of the Galaxy" to "a
similar (but distinct) Galactic-binary population,"

> (ii) I have found information that the data set contained
> 4-6 MBH binary MBH inspirals confusing:
> I would expect that the number of such signals injected into data
> was fixed. Does the range 4-6 was delivered to the MLDC participants
> but the number of such signals in the data was really fixed?
> Please clarify this.

The number of MBH signals injected in the data was determined randomly,
uniformly within the interval [4,6] at the time of generating the
challenge dataset. We have clarified the text in this regard.
 
> 2. To make the article more self-contained it would be useful
> to define all symbols that appear in Figure 2 and in Tables 1-3.
> To gain some space it should be possible to shorten the Introduction
> in the part describing the already published results
> of the first round of the MLDC.

In Fig. 2 the parameter definitions have been indicated directly in the
figure. In Tables 1-3 we have expanded the captions to define all symbols.

> 3. Is any explanation why the recovered SNR for the EMRI signals
> is so low compared to the true SNR (see Table 3),
> while for the MBH signals the recovered and true SNRs ale almost equal
> (see Tables 1 and 2)?

Yes, all the EMRI searches locked on secondary maxima of the likelihood:
that is, on different parameter sets that happen to yield a good (but
not optimal) correlation between template and signal. We have slightly
reworked the text to indicate this more clearly.

=== Responses to the second referee's report ===

> This paper reports on the Mock Lisa Data Challenges which are being used
> to prepare for LISA data analysis and as a proof of principle for the
> same. LISA data analysis is expected to present new challenges beyond
> the challenges currently being overcome for ground based detectors,
> which makes these Mock Data Challenges (MDCs) important and interesting
> to researchers throughout gravitational wave (and potentially
> gravitational) physics. This paper presents many insights into these new
> challenges that have arisen as a result the MDCs, as well as some
> preliminary solutions to some of these challenges. As such, it is an
> interesting and worthwhile addition to the literature. I am not happy,
> however, about the degree to which this article relies on the reader
> having read previous articles on LISA data analysis - it is always
> expected that new work will build on old, however, not even defining
> symbols that appear, but referring the reader to previous publications,
> is going to far in my opinion. Apart from this general observation, I
> have a number of specific comments that I suggest be addressed in the
> final version of this paper:

We thank the referee for his or her suggestions. We have worked to make
the paper more self-sufficient, within the Amaldi length constraints. In
particular, all symbols are now briefly defined where they the paper.

> 1) Abstract: "...data sets containing ... gravitational wave sources..."
> Presumably the data contains signals from gravitational wave sources,
> rather than the sources themselves.

Quite right. It's easy to forget this distinction, and the resulting
phrases can be grating to the ears of experts. We have fixed the abstract.

> 2) Abstract: This abstract could, with only a few more words, be much more
> informative, e.g.:
> - It is meaningless to report on the successful extraction of SMBH
> binary inspiral or EMRI waveforms without giving a range of SNRs.
> - Presumably the overlapping Galactic white-dwarf binaries were
> "distributed according to a realistic model"?

Very good suggestion. The uninformative abstracts reflects having been
written before the challenge-2 results were available. We have added
more information.

> 3) Introduction: Last sentence of paragraph one is difficult to parse. "It
> is therefore important to understand the data analysis challenge so as to
> demonstrate that LISA can ..." would be clearer, in my opinion.

We modified the text to implement this suggestion.

> 4) Introduction: In paragraph 3 "...staged on instrument noise alone." I
> suppose this means "simulated instrument noise". While the probability
> of a reader being confused into thinkin the noise is real is minimal,
> it can be eliminated entirely with one additional word.

Quite right. We have added the word.

> 5) Introduction: In paragraph 3, without discussing metrics for success, it
> not very meaningful to state that the signals from all source classes
> were successfully detected. See also earlier remarks about the SNR.

The referee is right that this statement is too broad without
qualification, so we have removed it. The text now states merely what
problems were posed in challenge 1 (which specifies, for instance, that
interfering-binary signals were ``loud'', and MBH signals were
``relatively loud''), and that at least one collaboration ``solved''
each problem.

> 6) Introduction: In paragraph 3, "... all challenges were solved by at least
> one group" seems to mean that there was a single group that solved ALL
> the challenges posed, and there may have been other groups that did so
> as well. I suspect that what is really meant is that each challenge
> was solved by at least one group.
 
Right: we have changed to ``each'', which is clearer.
 
> 7) Introduction: In paragraph 4, data set 2.1 did not contain a population
> of galactic binary systems. Probably, the authors meant simulated signals
> from an assumed population of galactic binaries. Likewise for data set
> 2.2.

This was fixed in the text by adding ``signal'' as needed.

> 8) Introduction: In paragraph 4, were the MBH binaries in set 2.2 spinning
> or not? Were different sky positions assumed? Different orientations? Why
> do I have to wait until the next section to find these details out?

It would take considerable space in the paper to describe how the binary
parameters were selected; but to answer the referee, the sky positions and
orientations were both random on spheres. We have added a sentence pointing
the reader to a separate proceeding where these matters are spelled out in
detail.

We did make an exception for the qualification of MBHs as nonspinning, which
is actually very important in this context. So all challenge-2 MBHs are now
described as ``nonspinning'' in this paper.

> 9) Introduction: In paragraph 4, I assume that the EMRI SNR quoted
> represents a matched filter on the full waveform?

Yes. Throughout the paper we have added ``optimal'' in front of ``SNR''
to make this distinction clear.
 
> 10) Introduction: In paragraph 4, it would be interesting to know a bit more
> about the simulated EMRI signals that were used. While it is fine to
> refer the reader to reference [4] for details, it would not hurt the
> discourse of this paper to offer a bit more than "EMRI" in describing
> the signals.

We have added a short description of the EMRI waveforms.

> 11) Introduction: In paragraph 5, it would again be useful to know what the
> metrics for success are in evaluating what was achieved. Or at least
> to tell the reader that they will be discussed in more detail in the
> next section.

We now point the reader to the rest of the paper, which can indeed be
understood as defining this "success".

> 12) Figure 1: It is unclear to me what is being correlated here - all
> parameters of the injected and detected binaries? Are all parameters
> treated equally, or is there a weighting? Also, there is insufficient
> information for me to judge the relevance of these histograms. I know
> that this is part of the point that this section is making, however,
> clearly the authors have drawn conclusions from graphs like these that
> I cannot. For instance, how am I to see that all searches do better by
> the Doppler metric criterion - MTJPL and PW AEI have higher numbers of
> perfect correlations, but is that the sole basis for judging the
> effectiveness of an algorith? If so, I don't need to see the rest of
> the bins for the searches. Given the caveats about false positives,
> there is a sense in which it is not even necessarily correct to assume
> that a higher number of perfect correlations is better.

We used two methods to match recovered and injected sources: The first uses
the noise weighted inner product between an injected source a and recovered
source b:

C_ab = (a|b)/sqrt((a|a)(b|b)). 

The second method used a signal metric (a la Owen), but one that is restricted
to the "doppler" parameters - sky location and GW frequency. This second
method is more forgiving as it is insensitive to errors in the extrinsic
phases - polarization, inclination, and orbital phase.

These pairing techniques are used to decide if a recovered source is a false
positive, which is just one of the many criteria we use to assess the quality
of the entry. On the other hand, it is hard to imagine a situation where a
higher number of good correlations does not indicate a superior entry, as it
would take incredible amount of luck to get a source correct by accident. The
caveats concerning false positives actually work in the other direction: since
we are using single source correlations to decide if a recovered signal
matches an injected signal, there is always the possibility that source
confusion will have pushed the best fit solution far enough away that the
pairing analysis flags a good solution as a false positive. In other words,
the correlation tends to *under* estimate how well the search algorithms have
performed.

We have amended the text to clarify these points.

> 13) Table 1: I personally find it unacceptable that I should have to refer
> to another paper to be able to understand the meaning of the columns of
> this table.

We have now added brief definitions for all symbols.
